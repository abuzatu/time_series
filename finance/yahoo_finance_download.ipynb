{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and analysing data from Yahoo Finance\n",
    "\n",
    "Taking the functions from utils.py, to make the code more modular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging level: NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE_NAME = \"/Users/abuzatu/Work/data/finance/stocks/tickers11.txt\"\n",
    "OUTPUT_FOLDER_NAME = \"/Users/abuzatu/Work/data/finance/stocks/processed_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADD_OUTSIDE_TRADING_HOURS = True\n",
    "ADD_DIVIDENDS_AND_STOCK_SPLITS = True\n",
    "AUTO_ADJUST = True\n",
    "PERIOD = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_DATE = [\n",
    "        # (\"10-01-01\", \"19-01-01\", \"1d\"),\n",
    "        (\"19-01-01\", \"19-01-04\", \"1d\"),\n",
    "        (\"19-01-04\", \"20-11-04\", \"1h\"),\n",
    "        (\"20-11-04\", \"20-11-18\", \"5m\"),\n",
    "        (\"20-11-18\", \"20-12-04\", \"2m\"),\n",
    "        (\"20-12-04\", \"20-12-11\", \"1m\"),\n",
    "        (\"20-12-11\", \"20-12-18\", \"1m\"),\n",
    "        (\"20-12-18\", \"20-12-25\", \"1m\"),\n",
    "        (\"20-12-25\", \"21-01-01\", \"1m\"),\n",
    "    ]\n",
    "#LIST_DATE = [\n",
    "#    (\"19-01-01\", \"19-01-04\", \"1d\"),\n",
    "#]\n",
    "date_start_all = LIST_DATE[0][0]\n",
    "date_end_all = LIST_DATE[-1][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_start_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_end_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stock_ticker = []\n",
    "try:\n",
    "    f = open(INPUT_FILE_NAME)\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.rstrip()\n",
    "        if line.startswith(\"#\"):\n",
    "            continue\n",
    "        list_stock_ticker.append(line)\n",
    "except IOError:\n",
    "    print(f\"File {INPUT_FILE_NAME} not accessible.\")\n",
    "finally:\n",
    "    f.close()\n",
    "list_stock_ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(stock_ticker, list_date, output_folder_name):\n",
    "    list_df = []\n",
    "    for s, e, interval in list_date:\n",
    "        string_date_start = f\"20{s} 00:00:00\"\n",
    "        string_date_end   = f\"20{e} 00:00:00\"\n",
    "        date_start = pd.to_datetime(string_date_start).tz_localize(LOCALIZE_US_STOCK_MARKET)\n",
    "        date_end = pd.to_datetime(string_date_end).tz_localize(LOCALIZE_US_STOCK_MARKET)\n",
    "        logger.info(f\"{stock_ticker} from {date_start} to {date_end} with interval {interval}\")\n",
    "        # fix a bug in yfinance of not applying the localization when this option is on\n",
    "        if ADD_OUTSIDE_TRADING_HOURS:\n",
    "            date_start += pd.Timedelta (5, \"h\")\n",
    "            date_end += pd.Timedelta (5, \"h\")\n",
    "\n",
    "        # read the data\n",
    "        df = read_data(stock_ticker,\n",
    "                   PERIOD,\n",
    "                   date_start,\n",
    "                   date_end,\n",
    "                   interval,\n",
    "                   ADD_OUTSIDE_TRADING_HOURS,\n",
    "                   ADD_DIVIDENDS_AND_STOCK_SPLITS,\n",
    "                   AUTO_ADJUST)\n",
    "        \n",
    "        #\n",
    "        logger.info(f\"len = {len(df)}\")\n",
    "        if len(df) > 0:\n",
    "            if stock_ticker == \"AMRH\":\n",
    "                if interval.endswith(\"h\") or interval.endswith(\"m\"):\n",
    "                    # ajust by the stock split of 4 stocks -> 1 stock\n",
    "                    apply_split(df, 4, 1)\n",
    "            # add to list\n",
    "            list_df.append(df)\n",
    "            # save for future\n",
    "            output_file_name = get_output_file_name(output_folder_name, s, e, interval, stock_ticker)\n",
    "            df.to_pickle(output_file_name )\n",
    "                  \n",
    "    # print(list_df[-1])\n",
    "    return pd.concat(list_df, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file and save to a file\n",
    "for stock_ticker in list_stock_ticker:\n",
    "    if False:\n",
    "        # do only for one ticker\n",
    "        if stock_ticker != \"EOSE\":\n",
    "            continue\n",
    "    print(f\"stock_ticker={stock_ticker}\")\n",
    "    # find automatically the range that we want\n",
    "    # we collect the data using the period max, then find the first date\n",
    "    # than depending on that date build the LIST_DATE\n",
    "    df = read_data(stock_ticker,\n",
    "                   \"max\",\n",
    "                   None,\n",
    "                   None,\n",
    "                   \"1d\",\n",
    "                   ADD_OUTSIDE_TRADING_HOURS,\n",
    "                   ADD_DIVIDENDS_AND_STOCK_SPLITS,\n",
    "                   AUTO_ADJUST)\n",
    "    datetime_end = df.index[0].tz_localize(None)\n",
    "    date_short = str(datetime_end.tz_localize(None).date())[2:]\n",
    "    list_date = []\n",
    "    if datetime_end < pd.to_datetime(\"2019-01-01\"):\n",
    "        list_date = [\n",
    "            (\"19-01-01\", \"19-01-05\", \"1d\"),\n",
    "            (\"19-01-05\", \"20-11-05\", \"1h\"),\n",
    "            (\"20-11-05\", \"20-11-18\", \"5m\"),\n",
    "            (\"20-11-18\", \"20-12-05\", \"2m\"),\n",
    "            (\"20-12-05\", \"20-12-11\", \"1m\"),\n",
    "            (\"20-12-11\", \"20-12-18\", \"1m\"),\n",
    "            (\"20-12-18\", \"20-12-25\", \"1m\"),\n",
    "            (\"20-12-25\", \"21-01-01\", \"1m\"),\n",
    "        ]\n",
    "    elif datetime_end < pd.to_datetime(\"2019-01-04\"):\n",
    "        list_date = [\n",
    "            (date_short, \"19-01-04\", \"1d\"),\n",
    "            (\"19-01-04\", \"20-11-04\", \"1h\"),\n",
    "            (\"20-11-04\", \"20-11-18\", \"5m\"),\n",
    "            (\"20-11-18\", \"20-12-04\", \"2m\"),\n",
    "            (\"20-12-04\", \"20-12-11\", \"1m\"),\n",
    "            (\"20-12-11\", \"20-12-18\", \"1m\"),\n",
    "            (\"20-12-18\", \"20-12-25\", \"1m\"),\n",
    "            (\"20-12-25\", \"21-01-01\", \"1m\"),\n",
    "        ]\n",
    "    elif datetime_end < pd.to_datetime(\"2020-11-04\"):\n",
    "        list_date = [\n",
    "            (date_short, \"20-11-04\", \"1h\"),\n",
    "            (\"20-11-04\", \"20-11-18\", \"5m\"),\n",
    "            (\"20-11-18\", \"20-12-04\", \"2m\"),\n",
    "            (\"20-12-04\", \"20-12-11\", \"1m\"),\n",
    "            (\"20-12-11\", \"20-12-18\", \"1m\"),\n",
    "            (\"20-12-18\", \"20-12-25\", \"1m\"),\n",
    "            (\"20-12-25\", \"21-01-01\", \"1m\"),\n",
    "        ]\n",
    "    elif datetime_end < pd.to_datetime(\"2020-11-18\"):\n",
    "        list_date = [\n",
    "            (date_short, \"20-11-18\", \"5m\"),\n",
    "            (\"20-11-18\", \"20-12-04\", \"2m\"),\n",
    "            (\"20-12-04\", \"20-12-11\", \"1m\"),\n",
    "            (\"20-12-11\", \"20-12-18\", \"1m\"),\n",
    "            (\"20-12-18\", \"20-12-25\", \"1m\"),\n",
    "            (\"20-12-25\", \"21-01-01\", \"1m\"),\n",
    "        ]\n",
    "    elif datetime_end < pd.to_datetime(\"2020-12-04\"):\n",
    "        list_date = [\n",
    "            (date_short, \"20-12-04\", \"2m\"),\n",
    "            (\"20-12-04\", \"20-12-11\", \"1m\"),\n",
    "            (\"20-12-11\", \"20-12-18\", \"1m\"),\n",
    "            (\"20-12-18\", \"20-12-25\", \"1m\"),\n",
    "            (\"20-12-25\", \"21-01-01\", \"1m\"),\n",
    "        ]\n",
    "    elif datetime_end < pd.to_datetime(\"2020-12-11\"):\n",
    "        list_date = [\n",
    "            (date_short, \"20-12-11\", \"1m\"),\n",
    "            (\"20-12-11\", \"20-12-18\", \"1m\"),\n",
    "            (\"20-12-18\", \"20-12-25\", \"1m\"),\n",
    "            (\"20-12-25\", \"21-01-01\", \"1m\"),\n",
    "        ]\n",
    "    elif datetime_end < pd.to_datetime(\"2020-12-18\"):\n",
    "        list_date = [\n",
    "            (date_short, \"20-12-18\", \"1m\"),\n",
    "            (\"20-12-18\", \"20-12-25\", \"1m\"),\n",
    "            (\"20-12-25\", \"21-01-01\", \"1m\"),\n",
    "        ]\n",
    "    elif datetime_end < pd.to_datetime(\"2020-12-25\"):\n",
    "        list_date = [\n",
    "            (date_short, \"20-12-25\", \"1m\"),\n",
    "            (\"20-12-25\", \"21-01-01\", \"1m\"),\n",
    "        ]\n",
    "    elif datetime_end < pd.to_datetime(\"2021-01-01\"):\n",
    "        list_date = [\n",
    "            (date_short, \"21-01-01\", \"1m\"),\n",
    "        ]\n",
    "    \n",
    "    if stock_ticker == \"LAZR\":\n",
    "        list_date = [\n",
    "            (\"19-03-25\", \"20-12-04\", \"1d\"),\n",
    "            (\"20-12-04\", \"20-12-11\", \"1m\"),\n",
    "            (\"20-12-11\", \"20-12-18\", \"1m\"),\n",
    "            (\"20-12-18\", \"20-12-25\", \"1m\"),\n",
    "            (\"20-12-25\", \"21-01-01\", \"1m\"),\n",
    "        ]\n",
    "    if stock_ticker == \"QS\":\n",
    "        list_date = [\n",
    "            (\"20-08-17\", \"20-12-04\", \"1d\"),\n",
    "            (\"20-12-04\", \"20-12-11\", \"1m\"),\n",
    "            (\"20-12-11\", \"20-12-18\", \"1m\"),\n",
    "            (\"20-12-18\", \"20-12-25\", \"1m\"),\n",
    "            (\"20-12-25\", \"21-01-01\", \"1m\"),\n",
    "        ]\n",
    "    if stock_ticker == \"GOEV\" or stock_ticker == \"XL\":\n",
    "        list_date = [\n",
    "            (\"19-04-16\", \"20-12-18\", \"1d\"),\n",
    "            (\"20-12-18\", \"20-12-25\", \"1m\"),\n",
    "            (\"20-12-25\", \"21-01-01\", \"1m\"),\n",
    "        ]\n",
    "    if stock_ticker == \"EOSE\":\n",
    "        list_date = [\n",
    "            (date_short, \"20-11-18\", \"1d\"),\n",
    "            (\"20-11-18\", \"20-12-04\", \"2m\"),\n",
    "            (\"20-12-04\", \"20-12-11\", \"1m\"),\n",
    "            (\"20-12-11\", \"20-12-18\", \"1m\"),\n",
    "            (\"20-12-18\", \"20-12-25\", \"1m\"),\n",
    "            (\"20-12-25\", \"21-01-01\", \"1m\"),\n",
    "        ]\n",
    "    \n",
    "    if False:\n",
    "        for date in list_date:\n",
    "            print(date)\n",
    "    #break\n",
    "    # continue\n",
    "    #\n",
    "    logging.info(f\"{stock_ticker}\")\n",
    "    df = get_df(stock_ticker, list_date, OUTPUT_FOLDER_NAME)\n",
    "    output_file_name = get_output_file_name(OUTPUT_FOLDER_NAME, date_start_all, date_end_all, \"al\", stock_ticker)\n",
    "    df.to_pickle(output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done one for some dates\n",
    "if False:\n",
    "    df = read_data(\"LAZR\",\n",
    "                   None,\n",
    "                   pd.to_datetime(\"2019-03-25\").tz_localize(LOCALIZE_US_STOCK_MARKET),\n",
    "                   pd.to_datetime(\"2020-11-04\").tz_localize(LOCALIZE_US_STOCK_MARKET),\n",
    "                   \"1h\",\n",
    "                   ADD_OUTSIDE_TRADING_HOURS,\n",
    "                   ADD_DIVIDENDS_AND_STOCK_SPLITS,\n",
    "                   AUTO_ADJUST)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done one for the entire period\n",
    "if False:\n",
    "    df = read_data(\"GOEV\",\n",
    "                   \"max\",\n",
    "                   None,\n",
    "                   None,\n",
    "                   \"1d\",\n",
    "                   ADD_OUTSIDE_TRADING_HOURS,\n",
    "                   ADD_DIVIDENDS_AND_STOCK_SPLITS,\n",
    "                   AUTO_ADJUST)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.Close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of concatenate two that changed name\n",
    "if False:\n",
    "    interval = \"al\"\n",
    "    output_file_name = get_output_file_name(OUTPUT_FOLDER_NAME, \"19-01-01\", \"20-12-31\", \"al\", \"AMRH\")\n",
    "    df1 = pd.read_pickle(output_file_name)\n",
    "    df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    interval = \"al\"\n",
    "    output_file_name = get_output_file_name(OUTPUT_FOLDER_NAME, \"20-12-31\", \"21-01-01\", \"al\", \"ENVB\")\n",
    "    df2 = pd.read_pickle(output_file_name)\n",
    "    df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    df = pd.concat([df1, df2], axis = 0)\n",
    "    df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    output_file_name = get_output_file_name(OUTPUT_FOLDER_NAME, \"19-01-01\", \"21-01-01\", \"al\", \"ENVB\")\n",
    "    df.to_pickle(output_file_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes buggy data with very large value in after-market, remove it\n",
    "df = df[df.Close < 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only the pre-market data\n",
    "get_df_pre_market(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only the after-market data\n",
    "get_df_after_market(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only the during-market data\n",
    "df2 = get_df_during_market(df)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the in-market data, add a fictious interval one minute before that ends on the open value\n",
    "# so that we can plot the open value as well\n",
    "df3 = add_interval_with_open(df2)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_plot = plot_interactive(df)\n",
    "final_plot.opts(xaxis = \"bottom\", title = f\"Stock price of {stock_ticker}\", show_legend = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_plot_volume = plot_interactive_volume(df)\n",
    "xaxis = None # \"bottom\"\n",
    "final_plot_volume.opts(xaxis = xaxis, yaxis = None, title = f\"Stock volume of {stock_ticker}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
