{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging level: NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Problem setting Forcasting monthly sales for tractors\n",
    "\n",
    "* All steps together in a [Word file](https://tanthiamhuat.files.wordpress.com/2015/12/step-by-step-guide-to-forecasting-through-arima-modeling.pdf).\n",
    "\n",
    "* Example code solved with [Jupyter Notebook in Python](http://ucanalytics.com/blogs/wp-content/uploads/2017/08/ARIMA-TimeSeries-Analysis-of-Tractor-Sales.html).\n",
    "\n",
    "* Original code on ucanalytics.com: [part 1](http://ucanalytics.com/blogs/forecasting-time-series-analysis-manufacturing-case-study-example-part-1/), [part 2](http://ucanalytics.com/blogs/time-series-decomposition-manufacturing-case-study-example-part-2/), [part 3](http://ucanalytics.com/blogs/step-by-step-graphic-guide-to-forecasting-through-arima-modeling-in-r-manufacturing-case-study-example), [part 4](http://ucanalytics.com/blogs/step-by-step-graphic-guide-to-forecasting-through-arima-modeling-in-r-manufacturing-case-study-example/), and [part 5](http://ucanalytics.com/blogs/how-effective-is-my-marketing-budget-regression-with-arima-errors-arimax-case-study-example-part-5/). \n",
    "\n",
    "* Tutorials on time series: [1](https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/), [2](https://www.digitalocean.com/community/tutorials/a-guide-to-time-series-visualization-with-python-3), [3](https://www.digitalocean.com/community/tutorials/a-guide-to-time-series-forecasting-with-arima-in-python-3), [4](https://www.blackarbs.com/blog/time-series-analysis-in-python-linear-models-to-garch/11/1/2016), \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1. Load directly from an online .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import requests\n",
    "\n",
    "url = 'http://www.ucanalytics.com/blogs/wp-content/uploads/2015/06/Tractor-Sales.csv'\n",
    "s = requests.get(url).text\n",
    "df = pd.read_csv(StringIO(s))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Load from a local csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_name = \"./Tractor-Sales.csv\"\n",
    "df = pd.read_csv(input_file_name)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data cleaning and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Clean missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    print(f\"{column}, {sum(df[column].isnull())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing data, but that if it were needed, we would remove the nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check again for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    print(f\"{column}, {sum(df[column].isnull())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Create a time series data frame\n",
    "\n",
    "By creating columns related to date time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type object is a string. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.1 Create the column by hand, assuming the 28th of the month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(x):\n",
    "    l = x.split(\"-\")\n",
    "    return f\"20{l[1]}-{l[0]}-28\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"] = df[\"Month-Year\"].map(lambda x: get_date(x))\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"date\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an aumamatic way to do that with a Pandas method, assuming the rows are already ordered by time with one entry per month. There are two options for frequency:\n",
    "\n",
    "* freq = \"M\" -> the date is set at the end of the month\n",
    "* freq = \"MS\" -> the date is set at the start of the month\n",
    "\n",
    "So there is an advantage over the method by hand from above, as it already knows for each month how many days there are and sets the count at the end of the month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"datetime\"] = pd.date_range(start = \"2003-01-28\", freq = \"M\", periods = len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check datetime has indeed the datetime64 type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add as columns year and month as numbers (numerical variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"year\"] = df.datetime.dt.year\n",
    "df[\"month\"] = df.datetime.dt.month\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add as column the month name as string (categorical variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "df[\"month_name\"] = df.month.map(lambda x: calendar.month_abbr[x])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the column of the number of tractors sold to y, for faster coding in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {\"Number of Tractor Sold\": \"y\"}, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only the subset of interesting variables and change the order as well if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, [\"datetime\", \"year\", \"month_name\", \"y\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the datetime as index, so that the dataframe is treated like a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"datetime\", inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (9,6))\n",
    "plt.plot(df.y)\n",
    "# plt.plot(df.datetime, df.y) # this would be needed if we had not set the index of the df to be datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The typical way to understand a time series and later predict is to decompose into three independent components that ar ethen summed, or multiplied:\n",
    "\n",
    "* trend (across years, a linear fit)\n",
    "* seasonality (across months or seasons, a sine wave fit maybe)\n",
    "* irregular remainder (ideally white noise)\n",
    "\n",
    "If the data contains many years, we can use in between trend and seasonality a fourth component, cycle, of patterns that repeat typically every 5-7 years.\n",
    "\n",
    "* trend (across years, a linear fit)\n",
    "* seasonality (across months or seasons, a sine wave fit maybe)\n",
    "* cycle (trends across many years, usually 5-7 years)\n",
    "* irregular remainder (ideally white noise)\n",
    "\n",
    "In our data a cycle is non existent. \n",
    "\n",
    "The key idea is that it is much easier to predict each component individually.\n",
    "\n",
    "The prediction p(t) = Trend(t) * Seasonality(t) * Remainder (t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Trend\n",
    "\n",
    "There are two steps: \n",
    "\n",
    "* 1. Explore visually with a rolling average what is the frequncy that gives a linear trend\n",
    "* 2. Perform a statistic test to disprove the null hypothesis that there is no trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Rolling averages\n",
    "\n",
    "Let's study the moving averages with 4, 6, 8, 12 months. The rolling average is computed directly with a Pandas function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_once(ax, df, column, nbRolling):\n",
    "    ax.plot(df.index, df[column], label='Original')\n",
    "    ax.plot(df.index, df[column].rolling(window=nbRolling).mean(), label = f\"{str(nbRolling).zfill(2)}-Months Rolling Mean\")\n",
    "    ax.plot(df.index, df[column].rolling(window=nbRolling).std(), label = f\"{str(nbRolling).zfill(2)}-Months Rolling Std\")\n",
    "    ax.set_xlabel(\"Years\")\n",
    "    ax.set_ylabel(\"Number of Tractors Sold\")\n",
    "    ax.set_title(f\"{str(nbRolling).zfill(2)}-Months Moving Average\")\n",
    "    ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize = (14, 10), sharey=False, sharex=False)\n",
    "column = \"y\"\n",
    "plot_once(axes[0][0], df, column, 4)\n",
    "plot_once(axes[0][1], df, column, 6)\n",
    "plot_once(axes[1][0], df, column, 8)\n",
    "plot_once(axes[1][1], df, column, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Dickey-Fuller Test\n",
    "\n",
    "Null Hypothesis: there is a trend, or the time series is non-stationary.\n",
    "    \n",
    "We calculate a test statistic and a confidence interval, we compare with a critical value. If the test statistic is less than the critical value, we can reject the null hypothesis and say the series is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Dickey-Fuller test:\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = adfuller(df.y, autolag='AIC')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = pd.Series(df_test[0:4], index=['Test Statistic', 'p-value', '#lags Used', 'Number of Observations Used'])\n",
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in df_test[4].items():\n",
    "    df_output[f\"Critical Value ({key})\"] = value\n",
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Results of Dickey-Fuller Test:\")\n",
    "logging.info(df_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test statistics is not smaller than the critical values, we we can not reject the null hypothesis, so there is a trend. \n",
    "\n",
    "The rms of the rolling average is almost constant in time. But the mean of the rolling average is clearly increasing, so there is a trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Seasonality\n",
    "\n",
    "First let's overlay all years to see how the number of orders varies every month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Done by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (9,6))\n",
    "for year in range(2003, 2015):\n",
    "    df_current = df.loc[(df.index >= pd.to_datetime(f\"{year}-Jan-01\")) & (df.index <= pd.to_datetime(f\"{year}-Dec-31\"))] \n",
    "    ax.plot(df_current.month_name, df_current.y, label = f\"{year}\")\n",
    "plt.legend(loc = \"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Done by Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales_data = pd.pivot_table(df, values = \"y\", columns = \"year\", index = \"month_name\")\n",
    "monthly_sales_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The months used as index appear in alphabetical order, so we want to reindex with the months in the chronological order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales_data = monthly_sales_data.reindex(index = ['Jan','Feb','Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "monthly_sales_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/box-plot-in-python-using-matplotlib/\n",
    "# edges are minimum (quartile of 0%) and maximum (quartile of 100%)\n",
    "# blue is the first quartile (25%) and last quartile (75%)\n",
    "# green is the median (50%)\n",
    "monthly_sales_data.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_sales_data = pd.pivot_table(df, values = \"y\", columns = \"month_name\", index = \"year\")\n",
    "yearly_sales_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The months are shown in alphabetical order, so let's re-order then in the chronological order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_sales_data = yearly_sales_data[['Jan','Feb','Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']]\n",
    "yearly_sales_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_sales_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/box-plot-in-python-using-matplotlib/\n",
    "# edges are minimum (quartile of 0%) and maximum (quartile of 100%)\n",
    "# blue is the first quartile (25%) and last quartile (75%)\n",
    "# green is the median (50%)\n",
    "yearly_sales_data.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Remainder\n",
    "\n",
    "The remaineder is what remains when we take off first the trend, then the seasonality. \n",
    "\n",
    "We can use either a multiplication, or an addition to obtain the total predictions:\n",
    "\n",
    "* Y(t) = Trend(t) * Seasonality(t) * Remainder(t)\n",
    "* Y(t) = Trend(t) + Seasonality(t) + Remainder(t)\n",
    "\n",
    "The results are usually the same.\n",
    "\n",
    "But be careful that this works on really clean data, like here. In real life this does not work that well, and more advanced models, like Holt-Winters seasonal method or ARIMA models are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Decomposition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 Decomposition via multiplication\n",
    "\n",
    "It is done for us by the statistical model library statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = sm.tsa.seasonal_decompose(df.y, model='multiplicative')\n",
    "fig = decomposition.plot()\n",
    "fig.set_figwidth(12)\n",
    "fig.set_figheight(8)\n",
    "fig.suptitle('Decomposition of multiplicative time series')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the three components:\n",
    "\n",
    "* 1. We fit a line (Linear Regression).\n",
    "\n",
    "* 2. We divide y(t)/y1(t) to obtain Sesonality(t) * Residual(t). If indeed we removed the year to year trend, the values should be similar for the months across years, so we take their mean. That gives Seasonality(t), or y2(t). \n",
    "\n",
    "* 3. We divide (y(t)/y1(t)) / y2(t)) to obtain the Remainder(t), or y3(t).\n",
    "\n",
    "We can predict for new values y(t) = y1(t) * y2(t) * y3(t)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 Decomposition via addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = sm.tsa.seasonal_decompose(df.y, model='additive')\n",
    "fig = decomposition.plot()\n",
    "fig.set_figwidth(12)\n",
    "fig.set_figheight(8)\n",
    "fig.suptitle('Decomposition of additive time series')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the three components:\n",
    "\n",
    "* 1. We fit a line (Linear Regression).\n",
    "\n",
    "* 2. We subtract y(t)-y1(t) to obtain Sesonality(t) + Residual(t). If indeed we removed the year to year trend, the values should be similar for the months across years, so we take their mean. That gives Seasonality(t), or y2(t). \n",
    "\n",
    "* 3. We subract (y(t) - y1(t)) - y2(t)) to obtain the Remainder(t), or y3(t).\n",
    "\n",
    "We can predict for new values y(t) = y1(t) + y2(t) + y3(t)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3 Calculate components\n",
    "\n",
    "We choose a hybrid method where y(t) = y1(t) * y2(t) + y3(t), given that if y3 is also a multiplication factor and not well modelled as wide noise it impacts percentage-wise more, but in absolute value it affects less. \n",
    "\n",
    "Via a linear regression fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_start = 2003\n",
    "year_end = 2014 # inclusive\n",
    "nb_months_per_year = 12\n",
    "X = np.array([i for i in range((year_end-year_start+1)*nb_months_per_year)])\n",
    "X = X.reshape(X.shape[0], 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.y.values\n",
    "lr = LinearRegression()\n",
    "regression = lr.fit(X, y)\n",
    "y1 = lr.predict(X)\n",
    "df[\"y1\"] = y1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y)\n",
    "plt.plot(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"y_div_y1\"] = df.y / df.y1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.y_div_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales_data = pd.pivot_table(df, values = \"y_div_y1\", columns = \"year\", index = \"month_name\")\n",
    "monthly_sales_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the average across years by giving up the columns variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales_data = pd.pivot_table(df, values = \"y_div_y1\", index = \"month_name\", aggfunc = np.mean)\n",
    "monthly_sales_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales_data = monthly_sales_data.reindex(index = ['Jan','Feb','Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "monthly_sales_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales_data.y_div_y1.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"y2\"] = df.month_name.map(monthly_sales_data.y_div_y1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"y1_times_y2\"] = df.y1 * df.y2\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.y)\n",
    "plt.plot(df.y1)\n",
    "plt.plot(df.y1_times_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"y3\"] = df.y - df.y1_times_y2\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df.y3, bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally this should be white noise, that we could model with a gaussian distribution. Let's assume it is the case, so let's get the mean and the standard deviation, and later predict by throwing a random number from a Gaussian distribution with these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y3_mu = np.mean(df.y3)\n",
    "y3_std = np.std(df.y3)\n",
    "logging.info(f\"y3_mu={y3_mu:.3f}, y3_std={y3_std:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"y1_times_y2_plus_y3\"] = df.y1 * df.y2 + df.y3\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.y)\n",
    "plt.plot(df.y1)\n",
    "plt.plot(df.y1_times_y2)\n",
    "plt.plot(df.y1_times_y2_plus_y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Predict for the next three years\n",
    "\n",
    "Let's create a new data frame for the following three years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_years = 3\n",
    "nb_months_per_year = 12\n",
    "df_predict = pd.DataFrame()\n",
    "df_predict[\"datetime\"] = pd.date_range(start = \"2015-01-28\", freq = \"M\", periods = nb_years * nb_months_per_year)\n",
    "df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict[\"month\"] = df_predict.datetime.dt.month\n",
    "df_predict[\"month_name\"] = df_predict.month.map(lambda x: calendar.month_abbr[x])\n",
    "df_predict[\"y\"] = 0.0 # dummy value\n",
    "df_predict.set_index(\"datetime\", inplace = True) # to interpret it as a time series\n",
    "df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict = np.array([i for i in range((year_end-year_start+1)*nb_months_per_year, (year_end-year_start+1+nb_years)*nb_months_per_year, 1)])\n",
    "display(X_predict.shape)\n",
    "display(X_predict)\n",
    "X_predict = X_predict.reshape(X_predict.shape[0], 1)\n",
    "display(X_predict.shape)\n",
    "display(X_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict[\"y1\"] = regression.predict(X_predict)\n",
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict[\"y2\"] = df_predict.month_name.map(monthly_sales_data.y_div_y1)\n",
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "df_predict[\"y3\"] = [random.gauss(y3_mu, y3_std) for i in range(len(df_predict))]\n",
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict[\"y1_times_y2\"] = df_predict.y1 * df_predict.y2\n",
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict[\"y1_times_y2_plus_y3\"] = df_predict.y1 * df_predict.y2 + df_predict.y3\n",
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_predict.y)\n",
    "plt.plot(df_predict.y1)\n",
    "plt.plot(df_predict.y1_times_y2)\n",
    "plt.plot(df_predict.y1_times_y2_plus_y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Overlay the original data and the predicted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict_2 = df_predict.loc[:, [\"y\", \"y1\", \"y1_times_y2\", \"y1_times_y2_plus_y3\"]]\n",
    "df_predict_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial_2 = df.loc[:, [\"y\", \"y1\", \"y1_times_y2\", \"y1_times_y2_plus_y3\"]]\n",
    "df_initial_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_initial_2, df_predict_2], axis = 0)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_all.y)\n",
    "plt.plot(df_all.y1)\n",
    "plt.plot(df_all.y1_times_y2)\n",
    "plt.plot(df_all.y1_times_y2_plus_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_all.y1)\n",
    "plt.plot(df_all.y1_times_y2)\n",
    "plt.plot(df_all.y1_times_y2_plus_y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ARIMA\n",
    "\n",
    "In real life this simple decomposition usually does not work that well, and more advanced models are used. \n",
    "\n",
    "One is ARIMA. The acronym stands for:\n",
    "* AR = Auto Regressive\n",
    "* I = Integrated\n",
    "* MA = Moving Average\n",
    "\n",
    "An implementation for this dataset in Python can be found [here](http://ucanalytics.com/blogs/wp-content/uploads/2017/08/ARIMA-TimeSeries-Analysis-of-Tractor-Sales.html). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
